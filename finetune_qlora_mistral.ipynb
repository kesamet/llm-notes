{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWzGlJcideZQ"
      },
      "source": [
        "# Efficient Fine-Tuning for Mistral-7b on a Single GPU using Ludwig\n",
        "\n",
        "Example: to train a foundation Mistral-7b for code generation\n",
        "\n",
        "This notebook is adapted from [Ludwig](https://colab.research.google.com/drive/1r4oSEwRJpYKBPM0M0RSh0pBEYK_gBKbe).\n",
        "\n",
        "## Fine-Tuning\n",
        "\n",
        "There are three different fine-tuning approaches in Ludwig:\n",
        "\n",
        "- **Full Fine-Tuning**\n",
        "- **Parameter Efficient Fine-Tuning (PEFT), e.g. LoRA**\n",
        "- **Quantization-Based Fine-Tuning (QLoRA)**\n",
        "\n",
        "In this notebook, we shall fine-tune using QLoRA given a single T4 GPU with 16GiB of GPU VRAM on Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAIqUUGnM72V"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvL1cL6wYtWz",
        "outputId": "8fad1298-969f-4e1e-deff-df5aacb46382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ludwig (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow --quiet\n",
        "!pip install ludwig --quiet\n",
        "!pip install ludwig[llm] --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "VUfuWbIPACZJ",
        "outputId": "e9d91abe-e3f2-4941-e13b-a2d83533da2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/huggingface/peft.git --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2SRHcKAJYuu"
      },
      "source": [
        "Enable text wrapping so we don't have to scroll horizontally and create a function to flush CUDA cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ht4eVWxB13QL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "def clear_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        model = None\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nXOIxmfbQHSz",
        "outputId": "9a5001d8-b226-462c-ceeb-e3ddfb9561b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token:··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import locale; locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "from ludwig.api import LudwigModel\n",
        "\n",
        "# HuggingFace Token\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = getpass.getpass(\"Token:\")\n",
        "assert os.environ[\"HUGGING_FACE_HUB_TOKEN\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV0D2rjRbk4z"
      },
      "source": [
        "## Import The Code Generation Dataset\n",
        "\n",
        "We shall load dataset `code_alpaca_20k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "m8FXsCwYbkHh",
        "outputId": "dd49fca0-4fc9-4f92-a17a-b450ccb70a8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import data_table; data_table.enable_dataframe_formatter()\n",
        "import numpy as np; np.random.seed(123)\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"https://raw.githubusercontent.com/sahil280114/codealpaca/master/data/code_alpaca_20k.json\")\n",
        "\n",
        "# We're going to create a new column called `split` where:\n",
        "# 90% will be assigned a value of 0 -> train set\n",
        "# 5% will be assigned a value of 1 -> validation set\n",
        "# 5% will be assigned a value of 2 -> test set\n",
        "# Calculate the number of rows for each split value\n",
        "total_rows = len(df)\n",
        "split_0_count = int(total_rows * 0.9)\n",
        "split_1_count = int(total_rows * 0.05)\n",
        "split_2_count = total_rows - split_0_count - split_1_count\n",
        "\n",
        "# Create an array with split values based on the counts\n",
        "split_values = np.concatenate([\n",
        "    np.zeros(split_0_count),\n",
        "    np.ones(split_1_count),\n",
        "    np.full(split_2_count, 2)\n",
        "])\n",
        "\n",
        "# Shuffle the array to ensure randomness\n",
        "np.random.shuffle(split_values)\n",
        "\n",
        "# Add the 'split' column to the DataFrame\n",
        "df['split'] = split_values\n",
        "df['split'] = df['split'].astype(int)\n",
        "\n",
        "# Here, we will use 1000 rows of this dataset.\n",
        "df = df.head(n=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew1H1nbDj9_Q"
      },
      "source": [
        "### Understanding The Code Alpaca Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "dAj8Zdr_F-kQ",
        "outputId": "844e255f-3508-470a-817b-d6ebe25a4255"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/881c4a0d49046431/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Create an array of length 5 which contains all even numbers between 1 and 10.\",\n\"\",\n\"arr = [2, 4, 6, 8, 10]\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Formulate an equation to calculate the height of a triangle given the angle, side lengths and opposite side length.\",\n\"\",\n\"Height of triangle = opposite side length * sin (angle) / side length\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Write a replace method for a string class which replaces the given string with a given set of characters.\",\n\"string = \\\"Hello World!\\\"\\nreplace_with = \\\"Greetings!\\\"\",\n\"def replace(self, replace_with):\\n    new_string = \\\"\\\"\\n    for char in self:\\n        if char == \\\" \\\":\\n            new_string += replace_with\\n        else:\\n            new_string += char\\n    return new_string\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Create an array of length 15 containing numbers divisible by 3 up to 45.\",\n\"\",\n\"arr = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45]\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Write a function to find the number of distinct states in a given matrix.\",\n\"matrix = [[1, 0, 0],\\n          [1, 0, 1],\\n          [1, 1, 1]]\",\n\"def find_num_distinct_states(matrix):\\n    states = set()\\n    for row in matrix:\\n        state = \\\"\\\".join([str(x) for x in row])\\n        states.add(state)\\n    return len(states)\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Create a nested loop to print every combination of numbers between 0-9\",\n\"\",\n\"for i in range(10):\\n    for j in range(10):\\n        print(i, j)\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"Write a function to find the maximum difference between two numbers in a given array.\",\n\"arr = [5, 3, 17, 11, 9]\",\n\"def max_difference(arr):\\n    max_diff = 0\\n    for i in range(len(arr)-1):\\n        diff = arr[i+1] - arr[i]\\n        if diff > max_diff:\\n            max_diff = diff\\n    return max_diff\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"Write a function to generate the nth Fibonacci number.\",\n\"< noinput >\",\n\"def fib(n):\\n    if n == 0:\\n        return 0\\n    elif n == 1:\\n        return 1\\n    else:\\n        return fib(n-2) + fib(n-1)\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"Write a class to represent a 2D point with x and y coordinates.\",\n\"\",\n\"class Point:\\n    def __init__(self, x, y):\\n        self.x = x \\n        self.y = y \\n   \\n    def __str__(self): \\n        return \\\"({0},{1})\\\".format(self.x, self.y)\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"Write code that removes spaces from a given string.\",\n\"string = \\\" A B C D \\\"\",\n\"def remove_spaces(string): \\n    return \\\"\\\".join(string.split())\",\n{\n            'v': 0,\n            'f': \"0\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"instruction\"], [\"string\", \"input\"], [\"string\", \"output\"], [\"number\", \"split\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-0fc6468e-1ca2-4ff2-8f80-d1597791568f\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fc6468e-1ca2-4ff2-8f80-d1597791568f')\"\n            title=\"Suggest charts.\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-0fc6468e-1ca2-4ff2-8f80-d1597791568f button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    ",
            "text/html": [
              "\n",
              "  <div id=\"df-6efe19a2-14c9-4a3b-be1d-80ce6c351bea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Create an array of length 5 which contains all...</td>\n",
              "      <td></td>\n",
              "      <td>arr = [2, 4, 6, 8, 10]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Formulate an equation to calculate the height ...</td>\n",
              "      <td></td>\n",
              "      <td>Height of triangle = opposite side length * si...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Write a replace method for a string class whic...</td>\n",
              "      <td>string = \"Hello World!\"\\nreplace_with = \"Greet...</td>\n",
              "      <td>def replace(self, replace_with):\\n    new_stri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Create an array of length 15 containing number...</td>\n",
              "      <td></td>\n",
              "      <td>arr = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a function to find the number of distinc...</td>\n",
              "      <td>matrix = [[1, 0, 0],\\n          [1, 0, 1],\\n  ...</td>\n",
              "      <td>def find_num_distinct_states(matrix):\\n    sta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Create a nested loop to print every combinatio...</td>\n",
              "      <td></td>\n",
              "      <td>for i in range(10):\\n    for j in range(10):\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Write a function to find the maximum differenc...</td>\n",
              "      <td>arr = [5, 3, 17, 11, 9]</td>\n",
              "      <td>def max_difference(arr):\\n    max_diff = 0\\n  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Write a function to generate the nth Fibonacci...</td>\n",
              "      <td>&lt; noinput &gt;</td>\n",
              "      <td>def fib(n):\\n    if n == 0:\\n        return 0\\...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Write a class to represent a 2D point with x a...</td>\n",
              "      <td></td>\n",
              "      <td>class Point:\\n    def __init__(self, x, y):\\n ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Write code that removes spaces from a given st...</td>\n",
              "      <td>string = \" A B C D \"</td>\n",
              "      <td>def remove_spaces(string): \\n    return \"\".joi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6efe19a2-14c9-4a3b-be1d-80ce6c351bea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6efe19a2-14c9-4a3b-be1d-80ce6c351bea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6efe19a2-14c9-4a3b-be1d-80ce6c351bea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0689172-c780-4a5a-9568-723f90ecf446\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0689172-c780-4a5a-9568-723f90ecf446')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0689172-c780-4a5a-9568-723f90ecf446 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         instruction  \\\n",
              "0  Create an array of length 5 which contains all...   \n",
              "1  Formulate an equation to calculate the height ...   \n",
              "2  Write a replace method for a string class whic...   \n",
              "3  Create an array of length 15 containing number...   \n",
              "4  Write a function to find the number of distinc...   \n",
              "5  Create a nested loop to print every combinatio...   \n",
              "6  Write a function to find the maximum differenc...   \n",
              "7  Write a function to generate the nth Fibonacci...   \n",
              "8  Write a class to represent a 2D point with x a...   \n",
              "9  Write code that removes spaces from a given st...   \n",
              "\n",
              "                                               input  \\\n",
              "0                                                      \n",
              "1                                                      \n",
              "2  string = \"Hello World!\"\\nreplace_with = \"Greet...   \n",
              "3                                                      \n",
              "4  matrix = [[1, 0, 0],\\n          [1, 0, 1],\\n  ...   \n",
              "5                                                      \n",
              "6                            arr = [5, 3, 17, 11, 9]   \n",
              "7                                        < noinput >   \n",
              "8                                                      \n",
              "9                               string = \" A B C D \"   \n",
              "\n",
              "                                              output  split  \n",
              "0                             arr = [2, 4, 6, 8, 10]      0  \n",
              "1  Height of triangle = opposite side length * si...      0  \n",
              "2  def replace(self, replace_with):\\n    new_stri...      0  \n",
              "3  arr = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33...      0  \n",
              "4  def find_num_distinct_states(matrix):\\n    sta...      0  \n",
              "5  for i in range(10):\\n    for j in range(10):\\n...      0  \n",
              "6  def max_difference(arr):\\n    max_diff = 0\\n  ...      0  \n",
              "7  def fib(n):\\n    if n == 0:\\n        return 0\\...      0  \n",
              "8  class Point:\\n    def __init__(self, x, y):\\n ...      0  \n",
              "9  def remove_spaces(string): \\n    return \"\".joi...      0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOW5fIpGGKf3"
      },
      "source": [
        "This dataset is meant to train a large language model to following instructions to produce code from natural language. Each row in the dataset consists of an:\n",
        "- `instruction` that describes a task\n",
        "- `input` when additional context is required for the instruction, and\n",
        "- the expected `output`.\n",
        "\n",
        "There are two types of instructions:\n",
        "\n",
        "#### **Type 1: Self-Sufficient**\n",
        "Instructions that are self-sufficient and require no additional context.\n",
        "```\n",
        "Instruction: \"Create an array of length 5 which contains all even numbers between 1 and 10.\"\n",
        "Input: None (instruction is self-sufficient)\n",
        "Output: \"arr = [2, 4, 6, 8, 10]\"\n",
        "```\n",
        "\n",
        "These examples are useful for training models to understand and follow instructions independently. They can be applied in various scenarios, including:\n",
        "\n",
        "- **Coding Tasks**: Teaching a model to generate code based on a clear instruction. For instance, generating a function to sort an array in a specific way.\n",
        "- **Mathematical Calculations**: Instructing a model to perform calculations or equations, such as finding the area of a shape given its dimensions.\n",
        "- **Data Manipulation**: Showing how to process data, like filtering, transforming, or aggregating data based on given criteria.\n",
        "- **Writing Instructions**: Training models to generate instructional content, like recipes, guides, or tutorials.\n",
        "\n",
        "#### **Type 2: Need Context**\n",
        "The instruction needs additional context provided in the `input` to complete the task.\n",
        "```\n",
        "Instruction: \"Write a replace method for a string class which replaces the given string with a given set of characters.\"\n",
        "Input: \"string = 'Hello World!' replace_with = 'Greetings!'\"\n",
        "Output:\n",
        "def replace(string, replace_with):\n",
        "    new_string = \"\"\n",
        "    for char in string:\n",
        "        if char == \" \":\n",
        "            new_string += replace_with\n",
        "        else:\n",
        "            new_string += char\n",
        "    return new_string\n",
        "```\n",
        "\n",
        "These examples are useful for training models to understand both the instruction and relevant context provided by the input. They find application in scenarios such as:\n",
        "\n",
        "- **Customized Code Generation**: Teaching a model to generate code that depends on specific inputs. For instance, creating a function to calculate a mathematical result given input parameters.\n",
        "- **Conditional Responses**: Guiding models to produce outputs that change based on different input conditions (think of a instruction that has different criteria for different letter grades, and then a conditional input like score = 85/100)\n",
        "- **Dynamic Content Creation**: Training models to generate content based on variable input, such as dynamic forms, letters, or responses to user queries.\n",
        "- **Configurable Processes**: Demonstrating how to perform tasks with customizable settings, like configuring a software component using provided parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eIyMPoSGFAN"
      },
      "source": [
        "As you can see below, the dataset is pretty balanced in terms of the number of examples of each type of instruction (also true for the full dataset with 20,000 rows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "REqFr-ngx0et",
        "outputId": "3c3c8602-8721-49ab-9853-5f006b9a1c48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of examples in the dataset: 100\n",
            "% of examples that are self-sufficient: 49.0\n",
            "% of examples that are need additional context: 51.0\n"
          ]
        }
      ],
      "source": [
        "num_self_sufficient = (df['input'] == '').sum()\n",
        "num_need_contex = df.shape[0] - num_self_sufficient\n",
        "\n",
        "# We are only using 100 rows of this dataset for this webinar\n",
        "print(f\"Total number of examples in the dataset: {df.shape[0]}\")\n",
        "\n",
        "print(f\"% of examples that are self-sufficient: {round(num_self_sufficient/df.shape[0] * 100, 2)}\")\n",
        "print(f\"% of examples that are need additional context: {round(num_need_contex/df.shape[0] * 100, 2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcM8DVrIKXWj"
      },
      "source": [
        "The other aspect worth noting is the average number of characters in each of the three columns `instruction`, `input` and `output` in the dataset. Typically, every 3-4 characters maps to a *token* (the basic building blocks that language models use to understand and analyze text data), and large language models have a limit on the number of tokens they can take as input.\n",
        "\n",
        "The maximum context length for the base LLaMA-2 model is 4096 tokens. Ludwig automatically truncates texts that are too long for the model, but looking at these sequence lengths, we should be able to fine-tune on full length examples without needing any truncation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "_3x3stdDKoCT",
        "outputId": "e6d6ff41-eec0-468f-cc80-ab84d64d31a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average number of tokens in the instruction column: 23\n",
            "Average number of tokens in the input column: 8\n",
            "Average number of tokens in the output column: 65\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculating the length of each cell in each column\n",
        "df['num_characters_instruction'] = df['instruction'].apply(lambda x: len(x))\n",
        "df['num_characters_input'] = df['input'].apply(lambda x: len(x))\n",
        "df['num_characters_output'] = df['output'].apply(lambda x: len(x))\n",
        "\n",
        "# Show Distribution\n",
        "df.hist(column=['num_characters_instruction', 'num_characters_input', 'num_characters_output'])\n",
        "\n",
        "# Calculating the average\n",
        "average_chars_instruction = df['num_characters_instruction'].mean()\n",
        "average_chars_input = df['num_characters_input'].mean()\n",
        "average_chars_output = df['num_characters_output'].mean()\n",
        "\n",
        "print(f'Average number of tokens in the instruction column: {(average_chars_instruction / 3):.0f}')\n",
        "print(f'Average number of tokens in the input column: {(average_chars_input / 3):.0f}')\n",
        "print(f'Average number of tokens in the output column: {(average_chars_output / 3):.0f}', end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU8iKtqwCc1b"
      },
      "source": [
        "## Fine-Tuning\n",
        "\n",
        "We shall fine-tune using QLoRA given a single T4 GPU with 16GiB of GPU VRAM on Colab. LoRA based fine-tuning or full fine-tuning typically requires 4 GPUs with 24GiB of GPU VRAM on a single node multi-GPU cluster and fine-tuning Deepspeed.\n",
        "\n",
        "To do this, the new parameters we're introducing are:\n",
        "\n",
        "- `adapter`: The PEFT method we want to use\n",
        "- `quantization`: Load the weights in int4 or int8 to reduce memory overhead.\n",
        "- `trainer`: We enable the `finetune` trainer and can configure a variety of training parameters such as epochs and learning rate.\n",
        "\n",
        "Note, there are a few additional preprocessing parameters we should set to ensure that training runs smoothly:\n",
        "\n",
        "```yaml\n",
        "preprocessing:\n",
        "  global_max_sequence_length: 512\n",
        "  split:\n",
        "    type: random\n",
        "    probabilities:\n",
        "    - 0.9\n",
        "    - 0.05\n",
        "    - 0.05\n",
        "```\n",
        "\n",
        "Some of the examples in the dataset have long sequences, so we set a `global_max_sequence_length` of 512 to ensure that we do not OOM.\n",
        "\n",
        "We also use 100% of data for training as the evaluation phase takes extra time and we will predict on new examples right afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "612decdfd24745a6bb6f740d214eb240",
            "1b2469e5c1044843a51da1a8c4f96547",
            "0347d76019fb450daf72e2fd98d5ee60",
            "4cf61f81bba940959a0b6864f77ab785",
            "b4af16563bcc4fdfbe3dd7814cc75771",
            "0f2647c4e7554318827be9205460bfc1",
            "08692b88cfa54ec9ac3ac6e32b64f104",
            "debd0b08d1174c89bc16692f19ec7bf4",
            "db8428fed20a4326a3c627f0a8437250",
            "bd08c93f71dc448a81f526c4053d30b3",
            "e2031470c6c748bda04dca67c0074367"
          ]
        },
        "id": "k-dtCIj73498",
        "outputId": "18b1d009-2dad-4af3-ca71-29078d055fa8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒════════════════════════╕\n",
            "INFO:ludwig.utils.print_utils:│ EXPERIMENT DESCRIPTION │\n",
            "INFO:ludwig.utils.print_utils:╘════════════════════════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:╒══════════════════╤═════════════════════════════════════════════════════════════════════════════════════════╕\n",
            "│ Experiment name  │ api_experiment                                                                          │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ Model name       │ run                                                                                     │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ Output directory │ /content/results/api_experiment_run_1                                                   │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ ludwig_version   │ '0.8.6'                                                                                 │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ command          │ ('/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py -f '                 │\n",
            "│                  │  '/root/.local/share/jupyter/runtime/kernel-e70476cf-3b72-4d17-94ed-f89269b423cf.json') │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ random_seed      │ 42                                                                                      │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ data_format      │ \"<class 'pandas.core.frame.DataFrame'>\"                                                 │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ torch_version    │ '2.1.0+cu118'                                                                           │\n",
            "├──────────────────┼─────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ compute          │ {   'arch_list': [   'sm_50',                                                           │\n",
            "│                  │                      'sm_60',                                                           │\n",
            "│                  │                      'sm_70',                                                           │\n",
            "│                  │                      'sm_75',                                                           │\n",
            "│                  │                      'sm_80',                                                           │\n",
            "│                  │                      'sm_86',                                                           │\n",
            "│                  │                      'sm_37',                                                           │\n",
            "│                  │                      'sm_90'],                                                          │\n",
            "│                  │     'devices': {   0: {   'device_capability': (7, 5),                                  │\n",
            "│                  │                           'device_properties': \"_CudaDeviceProperties(name='Tesla \"     │\n",
            "│                  │                                                \"T4', major=7, minor=5, \"                │\n",
            "│                  │                                                'total_memory=15101MB, '                 │\n",
            "│                  │                                                'multi_processor_count=40)',             │\n",
            "│                  │                           'gpu_type': 'Tesla T4'}},                                     │\n",
            "│                  │     'gencode_flags': '-gencode compute=compute_50,code=sm_50 -gencode '                 │\n",
            "│                  │                      'compute=compute_60,code=sm_60 -gencode '                          │\n",
            "│                  │                      'compute=compute_70,code=sm_70 -gencode '                          │\n",
            "│                  │                      'compute=compute_75,code=sm_75 -gencode '                          │\n",
            "│                  │                      'compute=compute_80,code=sm_80 -gencode '                          │\n",
            "│                  │                      'compute=compute_86,code=sm_86 -gencode '                          │\n",
            "│                  │                      'compute=compute_37,code=sm_37 -gencode '                          │\n",
            "│                  │                      'compute=compute_90,code=sm_90',                                   │\n",
            "│                  │     'gpus_per_node': 1,                                                                 │\n",
            "│                  │     'num_nodes': 1}                                                                     │\n",
            "╘══════════════════╧═════════════════════════════════════════════════════════════════════════════════════════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒═══════════════╕\n",
            "INFO:ludwig.utils.print_utils:│ LUDWIG CONFIG │\n",
            "INFO:ludwig.utils.print_utils:╘═══════════════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:User-specified config (with upgrades):\n",
            "\n",
            "INFO:ludwig.api:{   'adapter': {'type': 'lora'},\n",
            "    'base_model': 'alexsherstinsky/Mistral-7B-v0.1-sharded',\n",
            "    'generation': {'max_new_tokens': 512, 'temperature': 0.1},\n",
            "    'input_features': [{'name': 'instruction', 'type': 'text'}],\n",
            "    'ludwig_version': '0.8.6',\n",
            "    'model_type': 'llm',\n",
            "    'output_features': [{'name': 'output', 'type': 'text'}],\n",
            "    'preprocessing': {   'global_max_sequence_length': 512,\n",
            "                         'split': {   'probabilities': [0.9, 0.05, 0.05],\n",
            "                                      'type': 'random'}},\n",
            "    'prompt': {   'template': 'Below is an instruction that describes a task, '\n",
            "                              'paired with an input that provides further '\n",
            "                              'context. Write a response that appropriately '\n",
            "                              'completes the request.\\n'\n",
            "                              '### Instruction: {instruction}\\n'\n",
            "                              '### Input: {input}\\n'\n",
            "                              '### Response:'},\n",
            "    'quantization': {'bits': 4},\n",
            "    'trainer': {   'batch_size': 1,\n",
            "                   'epochs': 1,\n",
            "                   'eval_batch_size': 2,\n",
            "                   'gradient_accumulation_steps': 16,\n",
            "                   'learning_rate': 0.0004,\n",
            "                   'learning_rate_scheduler': {'warmup_fraction': 0.03},\n",
            "                   'type': 'finetune'}}\n",
            "INFO:ludwig.api:\n",
            "Full config saved to:\n",
            "/content/results/api_experiment_run_1/api_experiment/model/model_hyperparameters.json\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒═══════════════╕\n",
            "INFO:ludwig.utils.print_utils:│ PREPROCESSING │\n",
            "INFO:ludwig.utils.print_utils:╘═══════════════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.data.preprocessing:No cached dataset found at /content/06d5d38e731311eea24e0242ac1c000c.training.hdf5. Preprocessing the dataset.\n",
            "INFO:ludwig.data.preprocessing:Using full dataframe\n",
            "INFO:ludwig.data.preprocessing:Building dataset (it may take a while)\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.features.text_feature:Max length of feature 'None': 220 (without start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:Setting max length using dataset: 222 (including start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:max sequence length is 222 for feature 'None'\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.features.text_feature:Max length of feature 'output': 590 (without start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:Setting max length using dataset: 592 (including start and stop symbols)\n",
            "INFO:ludwig.features.text_feature:max sequence length is 592 for feature 'output'\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "INFO:ludwig.data.preprocessing:Building dataset: DONE\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed training set cache to /content/06d5d38e731311eea24e0242ac1c000c.training.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed validation set cache to /content/06d5d38e731311eea24e0242ac1c000c.validation.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing preprocessed test set cache to /content/06d5d38e731311eea24e0242ac1c000c.test.hdf5\n",
            "INFO:ludwig.data.cache.manager:Writing train set metadata to /content/06d5d38e731311eea24e0242ac1c000c.meta.json\n",
            "INFO:ludwig.api:\n",
            "Dataset Statistics\n",
            "INFO:ludwig.api:╒════════════╤═══════════════╤════════════════════╕\n",
            "│ Dataset    │   Size (Rows) │ Size (In Memory)   │\n",
            "╞════════════╪═══════════════╪════════════════════╡\n",
            "│ Training   │           900 │ 211.06 Kb          │\n",
            "├────────────┼───────────────┼────────────────────┤\n",
            "│ Validation │            50 │ 11.84 Kb           │\n",
            "├────────────┼───────────────┼────────────────────┤\n",
            "│ Test       │            50 │ 11.84 Kb           │\n",
            "╘════════════╧═══════════════╧════════════════════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒═══════╕\n",
            "INFO:ludwig.utils.print_utils:│ MODEL │\n",
            "INFO:ludwig.utils.print_utils:╘═══════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:Warnings and other logs:\n",
            "INFO:ludwig.models.llm:Loading large language model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "612decdfd24745a6bb6f740d214eb240",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.models.llm:Done.\n",
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "INFO:ludwig.models.llm:==================================================\n",
            "INFO:ludwig.models.llm:Trainable Parameter Summary For Fine-Tuning\n",
            "INFO:ludwig.models.llm:Fine-tuning with adapter: lora\n",
            "INFO:ludwig.models.llm:==================================================\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒══════════╕\n",
            "INFO:ludwig.utils.print_utils:│ TRAINING │\n",
            "INFO:ludwig.utils.print_utils:╘══════════╛\n",
            "INFO:ludwig.utils.print_utils:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.trainers.trainer:Creating fresh model training run.\n",
            "INFO:ludwig.trainers.trainer:Training for 900 step(s), approximately 1 epoch(s).\n",
            "INFO:ludwig.trainers.trainer:Early stopping policy: 5 round(s) of evaluation, or 4500 step(s), approximately 5 epoch(s).\n",
            "\n",
            "INFO:ludwig.trainers.trainer:Starting with step 0, epoch: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 900/900 [10:57<00:00,  1.42it/s, loss=0.0428]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.trainers.trainer:\n",
            "Running evaluation for step: 900, epoch: 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation valid: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
            "Evaluation test : 100%|██████████| 25/25 [00:21<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.trainers.trainer:Evaluation took 41.5310s\n",
            "\n",
            "INFO:ludwig.utils.metrics_printed_table:╒═══════════════════════╤════════════╤══════════════╤════════════╕\n",
            "│                       │      train │   validation │       test │\n",
            "╞═══════════════════════╪════════════╪══════════════╪════════════╡\n",
            "│ bleu                  │     0.2215 │       0.2254 │     0.2077 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ char_error_rate       │     1.2920 │       1.1644 │     1.1407 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ loss                  │     0.6108 │       0.5257 │     0.6521 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ next_token_perplexity │ 14500.0029 │   14574.0879 │ 15070.6562 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ perplexity            │ 31386.5449 │   31632.2598 │ 31646.5312 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rouge1_fmeasure       │     0.4195 │       0.4431 │     0.4375 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rouge1_precision      │     0.3035 │       0.3208 │     0.3211 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rouge1_recall         │     0.8273 │       0.8317 │     0.8272 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rouge2_fmeasure       │     0.3251 │       0.3397 │     0.3224 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rouge2_precision      │     0.2341 │       0.2454 │     0.2359 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rouge2_recall         │     0.6604 │       0.6538 │     0.6245 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rougeL_fmeasure       │     0.4021 │       0.4201 │     0.4091 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rougeL_precision      │     0.2903 │       0.3039 │     0.2996 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rougeL_recall         │     0.8006 │       0.7924 │     0.7775 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rougeLsum_fmeasure    │     0.4082 │       0.4274 │     0.4186 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rougeLsum_precision   │     0.2952 │       0.3094 │     0.3063 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ rougeLsum_recall      │     0.8088 │       0.8038 │     0.7970 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ sequence_accuracy     │     0.0000 │       0.0000 │     0.0000 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ token_accuracy        │     0.0088 │       0.0037 │     0.0035 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ word_error_rate       │     1.7100 │       1.6522 │     1.6395 │\n",
            "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
            "│ combined_loss         │     0.6108 │       0.5257 │     0.6521 │\n",
            "╘═══════════════════════╧════════════╧══════════════╧════════════╛\n",
            "INFO:ludwig.trainers.trainer:Evaluation validation metric: 'output' 'loss' improved.\n",
            "INFO:ludwig.trainers.trainer:'output' 'loss' decreased by inf.\n",
            "INFO:ludwig.trainers.trainer:New best model saved.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training: 100%|██████████| 900/900 [11:39<00:00,  1.29it/s, loss=0.0428]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒═════════════════╕\n",
            "INFO:ludwig.utils.print_utils:│ TRAINING REPORT │\n",
            "INFO:ludwig.utils.print_utils:╘═════════════════╛\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.api:╒══════════════════════════════╤════════════════════╕\n",
            "│ Validation feature           │ output             │\n",
            "├──────────────────────────────┼────────────────────┤\n",
            "│ Validation metric            │ loss               │\n",
            "├──────────────────────────────┼────────────────────┤\n",
            "│ Best model step              │ 900                │\n",
            "├──────────────────────────────┼────────────────────┤\n",
            "│ Best model epoch             │ 1                  │\n",
            "├──────────────────────────────┼────────────────────┤\n",
            "│ Best model's validation loss │ 0.5257427096366882 │\n",
            "├──────────────────────────────┼────────────────────┤\n",
            "│ Best model's test loss       │ 0.6520677208900452 │\n",
            "╘══════════════════════════════╧════════════════════╛\n",
            "INFO:ludwig.api:\n",
            "Finished: api_experiment_run\n",
            "INFO:ludwig.api:Saved to: /content/results/api_experiment_run_1\n",
            "INFO:ludwig.utils.print_utils:\n",
            "INFO:ludwig.utils.print_utils:╒══════════╕\n",
            "INFO:ludwig.utils.print_utils:│ FINISHED │\n",
            "INFO:ludwig.utils.print_utils:╘══════════╛\n",
            "INFO:ludwig.utils.print_utils:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "clear_cache()\n",
        "\n",
        "qlora_fine_tuning_config = yaml.safe_load(\n",
        "\"\"\"\n",
        "model_type: llm\n",
        "# We use a resharded model here since the base model does not have safetensors support.\n",
        "base_model: alexsherstinsky/Mistral-7B-v0.1-sharded\n",
        "\n",
        "input_features:\n",
        "  - name: instruction\n",
        "    type: text\n",
        "\n",
        "output_features:\n",
        "  - name: output\n",
        "    type: text\n",
        "\n",
        "prompt:\n",
        "  template: >-\n",
        "    Below is an instruction that describes a task, paired with an input\n",
        "    that provides further context. Write a response that appropriately\n",
        "    completes the request.\n",
        "\n",
        "    ### Instruction: {instruction}\n",
        "\n",
        "    ### Input: {input}\n",
        "\n",
        "    ### Response:\n",
        "\n",
        "generation:\n",
        "  temperature: 0.1\n",
        "  max_new_tokens: 512\n",
        "\n",
        "adapter:\n",
        "  type: lora\n",
        "\n",
        "quantization:\n",
        "  bits: 4\n",
        "\n",
        "preprocessing:\n",
        "  global_max_sequence_length: 512\n",
        "  split:\n",
        "    type: random\n",
        "    probabilities:\n",
        "    - 0.9\n",
        "    - 0.05\n",
        "    - 0.05\n",
        "\n",
        "trainer:\n",
        "  type: finetune\n",
        "  epochs: 1\n",
        "  batch_size: 1\n",
        "  eval_batch_size: 2\n",
        "  gradient_accumulation_steps: 16\n",
        "  learning_rate: 0.0004\n",
        "  learning_rate_scheduler:\n",
        "    warmup_fraction: 0.03\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "model = LudwigModel(config=qlora_fine_tuning_config, logging_level=logging.INFO)\n",
        "results = model.train(dataset=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "m2EBiULNz4-k",
        "outputId": "5de639fc-e729-48c8-a81f-7b6bac099a2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training_set_metadata.json\n"
          ]
        }
      ],
      "source": [
        "!ls /content/results/api_experiment_run/model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YkjcqMFMkwT"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Test the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ql8BdQm7Mora",
        "outputId": "815b73d2-a5ad-4304-de5e-c8788dce4409"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rPrediction:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.models.llm:Decoded text inputs for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create an array of length 5 which contains all even numbers between 1 and 10.\n",
            "### input: \n",
            "### response:\n",
            "INFO:ludwig.models.llm:Decoded generated output for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create an array of length 5 which contains all even numbers between 1 and 10.\n",
            "### input: \n",
            "### response: let arr = [2, 4, 6, 8, 10];\n",
            "INFO:ludwig.models.llm:Decoded text inputs for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create an array of length 15 containing numbers divisible by 3 up to 45.\n",
            "### input: \n",
            "### response:\n",
            "INFO:ludwig.models.llm:Decoded generated output for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create an array of length 15 containing numbers divisible by 3 up to 45.\n",
            "### input: \n",
            "### response: let arr = [];\n",
            "for (let i = 0; i < 15; i++) {\n",
            "    if (i % 3 === 0) {\n",
            "        arr.push(i);\n",
            "    }\n",
            "}\n",
            "console.log(arr);\n",
            "INFO:ludwig.models.llm:Decoded text inputs for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create a nested loop to print every combination of numbers between 0-9\n",
            "### input: \n",
            "### response:\n",
            "INFO:ludwig.models.llm:Decoded generated output for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create a nested loop to print every combination of numbers between 0-9\n",
            "### input: \n",
            "### response: for i in range(10):\n",
            "    for j in range(10):\n",
            "        print(i, j)\n",
            "INFO:ludwig.models.llm:Decoded text inputs for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: generate a function that computes the sum of the numbers in a given list\n",
            "### input: \n",
            "### response:\n",
            "INFO:ludwig.models.llm:Decoded generated output for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: generate a function that computes the sum of the numbers in a given list\n",
            "### input: \n",
            "### response: def sum_list(nums):\n",
            "    return sum(nums)\n",
            "INFO:ludwig.models.llm:Decoded text inputs for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create a class to store student names, ages and grades.\n",
            "### input: \n",
            "### response:\n",
            "INFO:ludwig.models.llm:Decoded generated output for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: create a class to store student names, ages and grades.\n",
            "### input: \n",
            "### response: class student:\n",
            "    def __init__(self, name, age, grade):\n",
            "        self.name = name\n",
            "        self.age = age\n",
            "        self.grade = grade\n",
            "INFO:ludwig.models.llm:Decoded text inputs for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: print out the values in the following dictionary.\n",
            "### input: my_dict = {\n",
            "  'name': 'john doe',\n",
            "  'age': 32,\n",
            "  'city': 'new york'\n",
            "}\n",
            "### response:\n",
            "INFO:ludwig.models.llm:Decoded generated output for the first example in batch: below is an instruction that describes a task, paired with an input that provides further context. write a response that appropriately completes the request.\n",
            "### instruction: print out the values in the following dictionary.\n",
            "### input: my_dict = {\n",
            "  'name': 'john doe',\n",
            "  'age': 32,\n",
            "  'city': 'new york'\n",
            "}\n",
            "### response: for key, value in my_dict.items():\n",
            "  print(key, ':', value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 100%|██████████| 1/1 [00:23<00:00, 23.05s/it]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ludwig.utils.tokenizers:Loaded HuggingFace implementation of alexsherstinsky/Mistral-7B-v0.1-sharded tokenizer\n",
            "WARNING:ludwig.utils.tokenizers:No padding token id found. Using eos_token as pad_token.\n",
            "/usr/local/lib/python3.10/dist-packages/ludwig/features/feature_utils.py:102: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.sum(np.log(sequence_probabilities))\n"
          ]
        }
      ],
      "source": [
        "test_examples = pd.DataFrame([\n",
        "      {\n",
        "            \"instruction\": \"Create an array of length 5 which contains all even numbers between 1 and 10.\",\n",
        "            \"input\": ''\n",
        "      },\n",
        "      {\n",
        "            \"instruction\": \"Create an array of length 15 containing numbers divisible by 3 up to 45.\",\n",
        "            \"input\": \"\",\n",
        "      },\n",
        "      {\n",
        "            \"instruction\": \"Create a nested loop to print every combination of numbers between 0-9\",\n",
        "            \"input\": \"\"\n",
        "      },\n",
        "      {\n",
        "            \"instruction\": \"Generate a function that computes the sum of the numbers in a given list\",\n",
        "            \"input\": \"\",\n",
        "      },\n",
        "      {\n",
        "            \"instruction\": \"Create a class to store student names, ages and grades.\",\n",
        "            \"input\": \"\",\n",
        "      },\n",
        "      {\n",
        "            \"instruction\": \"Print out the values in the following dictionary.\",\n",
        "            \"input\": \"my_dict = {\\n  'name': 'John Doe',\\n  'age': 32,\\n  'city': 'New York'\\n}\",\n",
        "      },\n",
        "])\n",
        "\n",
        "predictions = model.predict(test_examples, generation_config={'temperature': 0.1, 'max_new_tokens': 128})[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c6w7z8FjamYV",
        "outputId": "8e398349-6589-410d-8690-0ca9570ea5ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction: Create an array of length 5 which contains all even numbers between 1 and 10.\n",
            "Input: \n",
            "Generated Output:\n",
            "```\n",
            "let arr = [2, 4, 6, 8, 10];\n",
            "```\n",
            "\n",
            "\n",
            "Instruction: Create an array of length 15 containing numbers divisible by 3 up to 45.\n",
            "Input: \n",
            "Generated Output:\n",
            "```\n",
            "let arr = [];\n",
            "for (let i = 0; i < 15; i++) {\n",
            "    if (i % 3 === 0) {\n",
            "        arr.push(i);\n",
            "    }\n",
            "}\n",
            "console.log(arr);\n",
            "```\n",
            "\n",
            "\n",
            "Instruction: Create a nested loop to print every combination of numbers between 0-9\n",
            "Input: \n",
            "Generated Output:\n",
            "```\n",
            "for i in range(10):\n",
            "    for j in range(10):\n",
            "        print(i, j)\n",
            "```\n",
            "\n",
            "\n",
            "Instruction: Generate a function that computes the sum of the numbers in a given list\n",
            "Input: \n",
            "Generated Output:\n",
            "```\n",
            "def sum_list(nums):\n",
            "    return sum(nums)\n",
            "```\n",
            "\n",
            "\n",
            "Instruction: Create a class to store student names, ages and grades.\n",
            "Input: \n",
            "Generated Output:\n",
            "```\n",
            "class student:\n",
            "    def __init__(self, name, age, grade):\n",
            "        self.name = name\n",
            "        self.age = age\n",
            "        self.grade = grade\n",
            "```\n",
            "\n",
            "\n",
            "Instruction: Print out the values in the following dictionary.\n",
            "Input: my_dict = {\n",
            "  'name': 'John Doe',\n",
            "  'age': 32,\n",
            "  'city': 'New York'\n",
            "}\n",
            "Generated Output:\n",
            "```\n",
            "for key, value in my_dict.items():\n",
            "  print(key, ':', value)\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for input_with_prediction in zip(test_examples[\"instruction\"], test_examples[\"input\"], predictions[\"output_response\"]):\n",
        "    print(f\"Instruction: {input_with_prediction[0]}\")\n",
        "    print(f\"Input: {input_with_prediction[1]}\")\n",
        "    print(f\"Generated Output:\\n```\\n{input_with_prediction[2][0]}\\n```\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ1oBnTi64eR"
      },
      "source": [
        "## Notes\n",
        "\n",
        "**Explore LoRA or Full Fine-Tuning with Ludwig**\n",
        "\n",
        "- For LoRA based fine-tuning, just remove the `quantization` section in the config above.\n",
        "- For full fine-tuning, remove both the `quantization` and `adapter` sections above.\n",
        "\n",
        "Additionally, you will need to configure [DeepSpeed](https://www.deepspeed.ai/) for distributed model and data parallel training. This can be configured very easily with Ludwig, full docs [here](https://ludwig.ai/latest/configuration/backend/#deepspeed). Here's an example backend section of the Ludwig config:\n",
        "\n",
        "```yaml\n",
        "backend:\n",
        "  type: ray\n",
        "  trainer:\n",
        "    use_gpu: true\n",
        "    strategy:\n",
        "      type: deepspeed\n",
        "      zero_optimization:\n",
        "        stage: 3\n",
        "        offload_optimizer:\n",
        "          device: cpu\n",
        "          pin_memory: true\n",
        "      bf16:\n",
        "        enabled: true\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0347d76019fb450daf72e2fd98d5ee60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_debd0b08d1174c89bc16692f19ec7bf4",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db8428fed20a4326a3c627f0a8437250",
            "value": 8
          }
        },
        "08692b88cfa54ec9ac3ac6e32b64f104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f2647c4e7554318827be9205460bfc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2469e5c1044843a51da1a8c4f96547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2647c4e7554318827be9205460bfc1",
            "placeholder": "​",
            "style": "IPY_MODEL_08692b88cfa54ec9ac3ac6e32b64f104",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4cf61f81bba940959a0b6864f77ab785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd08c93f71dc448a81f526c4053d30b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e2031470c6c748bda04dca67c0074367",
            "value": " 8/8 [01:05&lt;00:00,  7.23s/it]"
          }
        },
        "612decdfd24745a6bb6f740d214eb240": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b2469e5c1044843a51da1a8c4f96547",
              "IPY_MODEL_0347d76019fb450daf72e2fd98d5ee60",
              "IPY_MODEL_4cf61f81bba940959a0b6864f77ab785"
            ],
            "layout": "IPY_MODEL_b4af16563bcc4fdfbe3dd7814cc75771"
          }
        },
        "b4af16563bcc4fdfbe3dd7814cc75771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd08c93f71dc448a81f526c4053d30b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8428fed20a4326a3c627f0a8437250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "debd0b08d1174c89bc16692f19ec7bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2031470c6c748bda04dca67c0074367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
