{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minbpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe.minbpe.base import Tokenizer, get_stats, merge\n",
    "\n",
    "\n",
    "class BasicTokenizer(Tokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        assert vocab_size >= 256, \"vocab_size is less than 256\"\n",
    "        num_merges = vocab_size - 256\n",
    "\n",
    "        ids = list(text.encode(\"utf-8\"))\n",
    "\n",
    "        merges = {}\n",
    "        vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "        for i in range(num_merges):\n",
    "            stats = get_stats(ids)\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = 256 + i\n",
    "            ids = merge(ids, pair, idx)\n",
    "            merges[pair] = idx\n",
    "            vocab[idx] = vocab[pair[0]] + vocab[pair[1]]\n",
    "            if verbose:\n",
    "                print(f\"merge {i+1}/{num_merges}: {pair} -> {idx} ({vocab[idx]}) had {stats[pair]} occurrences\")\n",
    "\n",
    "        self.merges = merges\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def encode(self, text):\n",
    "        ids = list(text.encode(\"utf-8\"))\n",
    "        while len(ids) >= 2:\n",
    "            stats = get_stats(ids)\n",
    "            pair = min(stats, key=lambda x: stats.get(x, float(\"inf\")))\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "            idx = self.merges[pair]\n",
    "            ids = merge(ids, pair, idx)\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text_bytes = b\"\".join(self.vocab[idx] for idx in ids)\n",
    "        text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"minbpe/tests/taylorswift.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge 1/44: (101, 32) -> 256 (b'e ') had 2981 occurrences\n",
      "merge 2/44: (44, 32) -> 257 (b', ') had 2961 occurrences\n",
      "merge 3/44: (100, 32) -> 258 (b'd ') had 2617 occurrences\n",
      "merge 4/44: (46, 32) -> 259 (b'. ') had 2560 occurrences\n",
      "merge 5/44: (114, 32) -> 260 (b'r ') had 2428 occurrences\n",
      "merge 6/44: (50, 48) -> 261 (b'20') had 2365 occurrences\n",
      "merge 7/44: (115, 32) -> 262 (b's ') had 2053 occurrences\n",
      "merge 8/44: (105, 110) -> 263 (b'in') had 2006 occurrences\n",
      "merge 9/44: (111, 110) -> 264 (b'on') had 1815 occurrences\n",
      "merge 10/44: (114, 105) -> 265 (b'ri') had 1805 occurrences\n",
      "merge 11/44: (116, 32) -> 266 (b't ') had 1802 occurrences\n",
      "merge 12/44: (116, 104) -> 267 (b'th') had 1737 occurrences\n",
      "merge 13/44: (101, 258) -> 268 (b'ed ') had 1736 occurrences\n",
      "merge 14/44: (257, 261) -> 269 (b', 20') had 1705 occurrences\n",
      "merge 15/44: (97, 110) -> 270 (b'an') had 1487 occurrences\n",
      "merge 16/44: (97, 114) -> 271 (b'ar') had 1360 occurrences\n",
      "merge 17/44: (101, 260) -> 272 (b'er ') had 1356 occurrences\n",
      "merge 18/44: (121, 32) -> 273 (b'y ') had 1248 occurrences\n",
      "merge 19/44: (97, 108) -> 274 (b'al') had 1164 occurrences\n",
      "merge 20/44: (267, 256) -> 275 (b'the ') had 1142 occurrences\n",
      "merge 21/44: (118, 268) -> 276 (b'ved ') had 1104 occurrences\n",
      "merge 22/44: (119, 105) -> 277 (b'wi') had 1049 occurrences\n",
      "merge 23/44: (101, 114) -> 278 (b'er') had 897 occurrences\n",
      "merge 24/44: (264, 32) -> 279 (b'on ') had 880 occurrences\n",
      "merge 25/44: (277, 102) -> 280 (b'wif') had 871 occurrences\n",
      "merge 26/44: (82, 101) -> 281 (b'Re') had 870 occurrences\n",
      "merge 27/44: (83, 280) -> 282 (b'Swif') had 867 occurrences\n",
      "merge 28/44: (111, 260) -> 283 (b'or ') had 859 occurrences\n",
      "merge 29/44: (99, 104) -> 284 (b'ch') had 816 occurrences\n",
      "merge 30/44: (269, 49) -> 285 (b', 201') had 811 occurrences\n",
      "merge 31/44: (111, 109) -> 286 (b'om') had 789 occurrences\n",
      "merge 32/44: (98, 272) -> 287 (b'ber ') had 752 occurrences\n",
      "merge 33/44: (32, 275) -> 288 (b' the ') had 748 occurrences\n",
      "merge 34/44: (97, 121) -> 289 (b'ay') had 744 occurrences\n",
      "merge 35/44: (101, 110) -> 290 (b'en') had 740 occurrences\n",
      "merge 36/44: (111, 114) -> 291 (b'or') had 737 occurrences\n",
      "merge 37/44: (274, 32) -> 292 (b'al ') had 705 occurrences\n",
      "merge 38/44: (101, 109) -> 293 (b'em') had 703 occurrences\n",
      "merge 39/44: (46, 10) -> 294 (b'.\\n') had 685 occurrences\n",
      "merge 40/44: (265, 101) -> 295 (b'rie') had 685 occurrences\n",
      "merge 41/44: (263, 103) -> 296 (b'ing') had 684 occurrences\n",
      "merge 42/44: (269, 50) -> 297 (b', 202') had 673 occurrences\n",
      "merge 43/44: (116, 105) -> 298 (b'ti') had 666 occurrences\n",
      "merge 44/44: (289, 108) -> 299 (b'ayl') had 654 occurrences\n"
     ]
    }
   ],
   "source": [
    "basic_tokenizer = BasicTokenizer()\n",
    "basic_tokenizer.train(text, 300, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 32,\n",
       " 119,\n",
       " 111,\n",
       " 114,\n",
       " 108,\n",
       " 100,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 63,\n",
       " 32,\n",
       " 40,\n",
       " 236,\n",
       " 149,\n",
       " 136,\n",
       " 235,\n",
       " 133,\n",
       " 149,\n",
       " 237,\n",
       " 149,\n",
       " 152,\n",
       " 236,\n",
       " 132,\n",
       " 184,\n",
       " 236,\n",
       " 154,\n",
       " 148,\n",
       " 33,\n",
       " 41,\n",
       " 32,\n",
       " 108,\n",
       " 111,\n",
       " 108,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 32,\n",
       " 240,\n",
       " 159,\n",
       " 152,\n",
       " 137]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = basic_tokenizer.encode(\"hello world!!!? (ì•ˆë…•í•˜ì„¸ìš”!) lol123 ðŸ˜‰\")\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world!!!? (ì•ˆë…•í•˜ì„¸ìš”!) lol123 ðŸ˜‰'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from minbpe.minbpe.base import Tokenizer, get_stats, merge\n",
    "\n",
    "GPT4_SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "\n",
    "class RegexTokenizer(Tokenizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.compiled_pattern = re.compile(GPT4_SPLIT_PATTERN)\n",
    "\n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        assert vocab_size >= 256, \"vocab_size is less than 256\"\n",
    "        num_merges = vocab_size - 256\n",
    "\n",
    "        # split text into chunks\n",
    "        text_chunks = re.findall(self.compiled_pattern, text)\n",
    "        ids = [list(chunk.encode(\"utf-8\")) for chunk in text_chunks] \n",
    "\n",
    "        merges = {}\n",
    "        vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "        for i in range(num_merges):\n",
    "            stats = {}\n",
    "            for chunk_ids in ids:\n",
    "                get_stats(chunk_ids, stats)\n",
    "            pair = max(stats, key=stats.get)\n",
    "            idx = 256 + i\n",
    "            ids = [merge(chunk_ids, pair, idx) for chunk_ids in ids]\n",
    "            merges[pair] = idx\n",
    "            vocab[idx] = vocab[pair[0]] + vocab[pair[1]]\n",
    "            if verbose:\n",
    "                print(f\"merge {i+1}/{num_merges}: {pair} -> {idx} ({vocab[idx]}) had {stats[pair]} occurrences\")\n",
    "\n",
    "        self.merges = merges\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def encode(self, text):\n",
    "        text_chunks = re.findall(self.compiled_pattern, text)\n",
    "        ids = []\n",
    "        for chunk in text_chunks:\n",
    "            chunk_ids = list(chunk.encode(\"utf-8\")) \n",
    "            while len(chunk_ids) >= 2:\n",
    "                stats = get_stats(chunk_ids)\n",
    "                pair = min(stats, key=lambda x: stats.get(x, float(\"inf\")))\n",
    "                if pair not in self.merges:\n",
    "                    break\n",
    "                idx = self.merges[pair]\n",
    "                chunk_ids = merge(chunk_ids, pair, idx)\n",
    "            ids.extend(chunk_ids)\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text_bytes = b\"\".join(self.vocab[idx] for idx in ids)\n",
    "        text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tests/taylorswift.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge 1/44: (101, 114) -> 256 (b'er') had 2359 occurrences\n",
      "merge 2/44: (50, 48) -> 257 (b'20') had 2187 occurrences\n",
      "merge 3/44: (111, 114) -> 258 (b'or') had 2076 occurrences\n",
      "merge 4/44: (105, 110) -> 259 (b'in') had 2006 occurrences\n",
      "merge 5/44: (101, 100) -> 260 (b'ed') had 1876 occurrences\n",
      "merge 6/44: (32, 116) -> 261 (b' t') had 1824 occurrences\n",
      "merge 7/44: (111, 110) -> 262 (b'on') had 1815 occurrences\n",
      "merge 8/44: (104, 101) -> 263 (b'he') had 1772 occurrences\n",
      "merge 9/44: (32, 83) -> 264 (b' S') had 1633 occurrences\n",
      "merge 10/44: (97, 114) -> 265 (b'ar') had 1519 occurrences\n",
      "merge 11/44: (97, 110) -> 266 (b'an') had 1487 occurrences\n",
      "merge 12/44: (32, 65) -> 267 (b' A') had 1335 occurrences\n",
      "merge 13/44: (261, 263) -> 268 (b' the') had 1169 occurrences\n",
      "merge 14/44: (97, 108) -> 269 (b'al') had 1164 occurrences\n",
      "merge 15/44: (114, 105) -> 270 (b'ri') had 1156 occurrences\n",
      "merge 16/44: (118, 260) -> 271 (b'ved') had 1104 occurrences\n",
      "merge 17/44: (115, 116) -> 272 (b'st') had 1089 occurrences\n",
      "merge 18/44: (119, 105) -> 273 (b'wi') had 1049 occurrences\n",
      "merge 19/44: (32, 82) -> 274 (b' R') had 1045 occurrences\n",
      "merge 20/44: (257, 49) -> 275 (b'201') had 981 occurrences\n",
      "merge 21/44: (32, 102) -> 276 (b' f') had 967 occurrences\n",
      "merge 22/44: (257, 50) -> 277 (b'202') had 952 occurrences\n",
      "merge 23/44: (32, 84) -> 278 (b' T') had 934 occurrences\n",
      "merge 24/44: (102, 116) -> 279 (b'ft') had 934 occurrences\n",
      "merge 25/44: (97, 121) -> 280 (b'ay') had 900 occurrences\n",
      "merge 26/44: (32, 34) -> 281 (b' \"') had 882 occurrences\n",
      "merge 27/44: (273, 279) -> 282 (b'wift') had 870 occurrences\n",
      "merge 28/44: (101, 116) -> 283 (b'et') had 852 occurrences\n",
      "merge 29/44: (264, 282) -> 284 (b' Swift') had 817 occurrences\n",
      "merge 30/44: (99, 104) -> 285 (b'ch') had 797 occurrences\n",
      "merge 31/44: (98, 256) -> 286 (b'ber') had 797 occurrences\n",
      "merge 32/44: (97, 116) -> 287 (b'at') had 790 occurrences\n",
      "merge 33/44: (111, 109) -> 288 (b'om') had 789 occurrences\n",
      "merge 34/44: (101, 115) -> 289 (b'es') had 743 occurrences\n",
      "merge 35/44: (101, 110) -> 290 (b'en') had 724 occurrences\n",
      "merge 36/44: (101, 109) -> 291 (b'em') had 699 occurrences\n",
      "merge 37/44: (34, 46) -> 292 (b'\".') had 693 occurrences\n",
      "merge 38/44: (32, 40) -> 293 (b' (') had 685 occurrences\n",
      "merge 39/44: (46, 10) -> 294 (b'.\\n') had 684 occurrences\n",
      "merge 40/44: (259, 103) -> 295 (b'ing') had 684 occurrences\n",
      "merge 41/44: (108, 258) -> 296 (b'lor') had 680 occurrences\n",
      "merge 42/44: (32, 77) -> 297 (b' M') had 662 occurrences\n",
      "merge 43/44: (105, 103) -> 298 (b'ig') had 655 occurrences\n",
      "merge 44/44: (32, 262) -> 299 (b' on') had 654 occurrences\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer()\n",
    "regex_tokenizer.train(text, 300, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[263,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 32,\n",
       " 119,\n",
       " 111,\n",
       " 114,\n",
       " 108,\n",
       " 100,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 63,\n",
       " 293,\n",
       " 236,\n",
       " 149,\n",
       " 136,\n",
       " 235,\n",
       " 133,\n",
       " 149,\n",
       " 237,\n",
       " 149,\n",
       " 152,\n",
       " 236,\n",
       " 132,\n",
       " 184,\n",
       " 236,\n",
       " 154,\n",
       " 148,\n",
       " 33,\n",
       " 41,\n",
       " 32,\n",
       " 108,\n",
       " 111,\n",
       " 108,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 32,\n",
       " 240,\n",
       " 159,\n",
       " 152,\n",
       " 137]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = regex_tokenizer.encode(\"hello world!!!? (ì•ˆë…•í•˜ì„¸ìš”!) lol123 ðŸ˜‰\")\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world!!!? (ì•ˆë…•í•˜ì„¸ìš”!) lol123 ðŸ˜‰'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# vanilla, non-DDP run\n",
    "ddp_rank = 0\n",
    "ddp_local_rank = 0\n",
    "ddp_world_size = 1\n",
    "master_process = True\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embed, 4 * config.n_embed)\n",
    "        self.gelu = nn.GELU(approximate=\"tanh\")\n",
    "        self.c_proj = nn.Linear(4 * config.n_embed, config.n_embed)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CasualSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embed % config.n_head == 0\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embed = config.n_embed\n",
    "        self.c_attn = nn.Linear(config.n_embed, 3 * config.n_embed)  # qkv projections\n",
    "        self.c_proj = nn.Linear(config.n_embed, config.n_embed)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embed, dim=2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_casual=True)\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)  #  (B, T, C)\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embed)\n",
    "        self.attn = CasualSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embed)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024  # max sequence length\n",
    "    vocab_size: int = 50257  # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 12  # number of layers\n",
    "    n_head: int = 12  # number of heads\n",
    "    n_embd: int = 768  # embedding dimension\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(\n",
    "            dict(\n",
    "                wte=nn.Embedding(config.vocab_size, config.n_embed),\n",
    "                wpe=nn.Embedding(config.block_size, config.n_embed),\n",
    "                h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "                ln_f=nn.LayerNorm(config.n_embed),\n",
    "            )\n",
    "        )\n",
    "        self.lm_head = nn.Linear(config.n_embed, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight sharing scheme\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, \"NANOGPT_SCALE_INIT\"):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "\n",
    "        x = tok_emb + pos_emb\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.transformer.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained model weights from huggingface.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, device_type):\n",
    "        # start with all of the candidate parameters (that require grad)\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {\"params\": decay_params, \"weight_decay\": weight_decay},\n",
    "            {\"params\": nodecay_params, \"weight_decay\": 0.0},\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        if master_process:\n",
    "            print(\n",
    "                f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\"\n",
    "            )\n",
    "            print(\n",
    "                f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\"\n",
    "            )\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = \"fused\" in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == \"cuda\"\n",
    "        if master_process:\n",
    "            print(f\"using fused AdamW: {use_fused}\")\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\n",
    "    \"tok_embeddings.weight\",\n",
    "    \"layers.0.attention.wq.weight\",\n",
    "    \"layers.0.attention.wk.weight\",\n",
    "    \"layers.0.attention.wv.weight\",\n",
    "    \"layers.0.attention.wo.weight\",\n",
    "    \"layers.0.feed_forward.w1.weight\",\n",
    "    \"layers.0.feed_forward.w3.weight\",\n",
    "    \"layers.0.feed_forward.w2.weight\",\n",
    "    \"layers.0.attention_norm.weight\",\n",
    "    \"layers.0.ffn_norm.weight\",\n",
    "    \"layers.1.attention.wq.weight\",\n",
    "    \"layers.1.attention.wk.weight\",\n",
    "    \"layers.1.attention.wv.weight\",\n",
    "    \"layers.1.attention.wo.weight\",\n",
    "    \"layers.1.feed_forward.w1.weight\",\n",
    "    \"layers.1.feed_forward.w3.weight\",\n",
    "    \"layers.1.feed_forward.w2.weight\",\n",
    "    \"layers.1.attention_norm.weight\",\n",
    "    \"layers.1.ffn_norm.weight\",\n",
    "    \"layers.2.attention.wq.weight\"\n",
    "]\n",
    "\n",
    "{'dim': 4096,\n",
    " 'n_layers': 32,\n",
    " 'n_heads': 32,\n",
    " 'n_kv_heads': 8,\n",
    " 'vocab_size': 128256,\n",
    " 'multiple_of': 1024,\n",
    " 'ffn_dim_multiplier': 1.3,\n",
    " 'norm_eps': 1e-05,\n",
    " 'rope_theta': 500000.0}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        hidden_dim = 4 * config.n_embd\n",
    "        hidden_dim = int(2 * hidden_dim / 3)  # Applying your specific transformation\n",
    "        if config.ffn_dim_multiplier is not None:\n",
    "            hidden_dim = int(config.ffn_dim_multiplier * hidden_dim)\n",
    "\n",
    "        self.w1 = nn.Linear(config.n_embed, hidden_dim, bias=False)\n",
    "        self.w3 = nn.Linear(config.n_embed, hidden_dim, bias=False)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.w2 = nn.Linear(hidden_dim, config.n_embed, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        swish = self.w1(self.silu(x))\n",
    "        x_v = self.w3(x)\n",
    "        x = swish * x_v\n",
    "        x = self.w2(x)\n",
    "        return x\n",
    "    \n",
    "# https://medium.com/@vi.ai_/exploring-and-building-the-llama-3-architecture-a-deep-dive-into-components-coding-and-43d4097cfbbb\n",
    "\n",
    "class CasualSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_embed = config.n_embed\n",
    "        self.seq_len = config.block_size\n",
    "        self.rope_theta = config.rope_theta\n",
    "\n",
    "    def _precomputed_theta_pos_frequencies(self, device):\n",
    "        # As written in the paper, the dimension of embedding must be even\n",
    "        assert self.n_embed % 2 == 0, \"n_embed must be even\"\n",
    "        # Built the theta parameters\n",
    "        # According to the formula theta_i = 10000 ^ (-2(i-1)/dim) for i = [1,2,3,..dim/2]\n",
    "        theta = 1.0 / (self.rope_theta ** (torch.arange(0, self.n_embed, 2) / self.n_embed)).to(device)  # Shape : (head_dim / 2)\n",
    "        # Construct the positions (the \"m\" parameter)\n",
    "        m = torch.arange(self.seq_len, device=device)  # shape: (seq_len)\n",
    "        # multiply each theta by each position using the outer product\n",
    "        freq = torch.outer(m, theta).float()  # (seq_len, head_dim / 2)\n",
    "        # we can computer complex numbers in the polar form c = R * exp(i * m * theta), where R = 1 as follow\n",
    "        freq_complex = torch.polar(torch.ones_like(freq), freq)  # (seq_len, head_dim / 2)\n",
    "        return freq_complex\n",
    "\n",
    "    def _apply_rotary_embeddings(self, x, freq_complex):\n",
    "        # TODO: batch?\n",
    "        q_per_token_split_into_pairs = x.view(x.shape[0], -1, 2)\n",
    "        q_per_token_as_complex = torch.view_as_complex(q_per_token_split_into_pairs)\n",
    "        q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex * freq_complex[:len(x)])\n",
    "        q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)\n",
    "        return q_per_token_rotated\n",
    "\n",
    "    def forward(self, x):\n",
    "        freq_complex = self._precomputed_theta_pos_frequencies(x.device)\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, dim: int, eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # The gamma parameter\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x: torch.Tensor):\n",
    "        # (B, seq_len, dim) -> (B, seq_len, 1)\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # dim : (B, seq_len, dim) -> (B, seq_len, dim)\n",
    "        return self.weight * self._norm(x.float()).type_as(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Encoder block\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.rmsnorm_1 = RMSNorm(config.n_embed, eps=config.norm_eps)\n",
    "        self.attn = CasualSelfAttention(config)\n",
    "        self.rmsnorm_2 = RMSNorm(config.n_embed, eps=config.norm_eps)\n",
    "        self.ff = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.rmsnorm_1(x))\n",
    "        x = x + self.ff(self.rmsnorm_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Llama3Config:\n",
    "    block_size: int = 4096  # max sequence length\n",
    "    vocab_size: int = 128256  # number of tokens: 128,000 BPE merges + 256 bytes tokens\n",
    "    n_layer: int = 32  # number of layers\n",
    "    n_head: int = 32  # number of heads\n",
    "    n_embd: int = 4096  # embedding dimension = dim\n",
    "    multiple_of: int = 1024\n",
    "    ffn_dim_multiplier: float = 1.3\n",
    "    norm_eps: float = 1e-5\n",
    "    rope_theta: float = 500000.0\n",
    "\n",
    "\n",
    "class Llama3(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(\n",
    "            dict(\n",
    "                wte=nn.Embedding(config.vocab_size, config.n_embed),\n",
    "                wpe=nn.Embedding(config.block_size, config.n_embed),\n",
    "                h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "                ln_f=nn.LayerNorm(config.n_embed),\n",
    "            )\n",
    "        )\n",
    "        self.lm_head = nn.Linear(config.n_embed, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight sharing scheme\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, \"NANOGPT_SCALE_INIT\"):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "\n",
    "        x = tok_emb + pos_emb\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.transformer.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
